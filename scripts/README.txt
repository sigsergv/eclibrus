Задача
======

На входе пачка архивов вида XXXXX-YYYYY.zip, где XXXXX и YYYYY границы диапазона 
идентификаторов, внутри архива лежат fb2-файлы.

На выходе нужно получить архивы (или каталоги) с файлами без дупликатов (прошлых версий итп).

План решения
============

1. скачать бэкапы базы с сайта lib.rus.ec (http://lib.rus.ec/sql/)
2. импортировать бэкапы в локальную sqlite-базу данных
3. считать индексы всех файлов из исходных архивов
4. сформировать итоговый список валидных файлов, при необходимости «спуститься» по цепочке
   исправлений и найти файлы, которые есть в исходных архивах
5. скопировать валидные файлы или загнать их в один архив, или скопировать со сжатием

Возможно, не стоит вручную все файлы сканировать, а воспользоваться данными из базы 
данных (автор, название, жанр итп). В этом случае итоговая программа может получиться совсем простой.

Книги
=====

Для подготовки архива необходим также набор запакованных fb2-файлов с именами, 
состоящими из идентификатора в базе. Скачать такие файлы можно с помощью 
торрента http://torrent.rus.ec/viewtopic.php?t=19 , например.

Последовательность действий
===========================

Подготовка база данных
----------------------

Сначала нужно подготовить базу данных на основе бэкапов сайта либрусека, для этого запускаем 
в каталоге `scripts` команду:

    make -f Makefile.in library.db

В процессе выполнения будут скачаны нужные файлы с сайта либрусека, распакованы, 
распарсены; также будет создана sqlite-база в файле library.db.

Если в каталоге лежат файлы от предыдущего запуска, их можно очистить командой:

    make -f Makefile.in clean-sql clean-gz

Актуализация базы
-----------------

Теперь нужно скачать торрент с архивами, эти архивы содержат в себе все fb2-файлы, когда-либо попадавшие в либрусек,
включая заменённые и обновлённые; поэтому нужно очистить эти архивы. Это делается скриптом ``cleanup-archives``:

    ./cleanup-archives

Но вначале нужно этот скрипт подредактировать: в переменную ``indir`` прописать путь до каталога с XXXXXX-YYYYYY.zip 
файлами; в переменную ``outdir`` — путь до каталога, куда будут в итоге записаны «валидные» файлы и готовая база данных.

После чего запускаем скрипт, он работает довольно долго, час или больше. В конце выполнения в каталоге ``outdir`` будет 
создано 20 каталогов с именами 01, 02, ..., 20, в каждом из которых будет лежать порядка 8-10 тыс. незапакованных 
fb2-файлов.

Упаковка архивов
----------------

Теперь файлы нужно запаковать, для этого заходим в каталог ``outdir``, копируем туда файл ``Makefile`` (который находится
в том же каталоге, что и файл README.txt, который вы читаете), а затем выполняем команду:

    make clear-zip compress

Этот скрипт работает около двух-трёх часов, после его выполнения в каталоге ``outdir`` будут лежать двадцать файлов 
вида XX.zip, каждый размером около 2.5 ГБ. Эти файлы содержат все валидные fb2-файлы на момент выполнения скриптов.


Подготовка итогового индекса
----------------------------

К данному моменту у нас есть 20 архивов, в которых лежит куча файлов вида xxxxx.fb2, где xxxxx — это идентификатор книги 
в базе либрусека. Также у нас есть файл ``library.db``, в котором находится копия актуальной базы либрусека, однако эта
база для дальнейшего использования малопригодна, так как там есть упоминания вообще всех книг, включая обновлённые, а ещё
там нет нормального поискового индекса. Поэтому сейчас нужно сгенерить итоговую базу, в которой будут только нужные 
нам данные.

Для генерации итогового индекса используется скрипт ``create-index``, в нём также нужно сначала модифицировать две 
переменные: ``indir`` — путь до каталога, где лежат полученные на прошлом шаге архивы (01.zip, 02.zip и т.д.); 
``outdir`` — путь до каталога, где будет создана финальная база данных (это будет файл ``librusec.eclib``). 
Отредактировали скрипт, теперь запускаем:

    ./create-index
